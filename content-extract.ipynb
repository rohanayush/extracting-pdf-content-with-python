{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages, extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LTTextBoxHorizontal(0) 34.000,1046.000,207.991,1076.000 'Rohan Ayush\\n\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(1) 32.000,987.000,257.245,1033.000 'Data Scientist: Expert in Data \\nAnallysis and ML Modeling (Python, \\nR) and Data Visualization (Tableau)\\n'>\n",
      "<LTTextBoxHorizontal(2) 32.000,931.000,211.437,964.000 'Address- Dhurwa,Ranchi, \\nJharkhand-834004\\r\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(3) 32.000,859.000,282.071,910.000 'Email -rohanayush05@outlook.com\\nPhone - +91 7992496642\\n\\nLinkedIN\\n\\n'>\n",
      "<LTTextBoxHorizontal(4) 59.000,794.000,227.285,814.000 'WORK PROJECTS\\n'>\n",
      "<LTTextBoxHorizontal(5) 346.000,1026.000,580.364,1082.000 'EXPERIENCE\\r\\n\\nDCT,Pune - ( Software Engineer )\\n\\nApril,2023  - September,2023\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(6) 346.000,972.000,571.443,1005.000 'Freelance ( Angular Developer )\\n\\nDecember 2022-  March -2023\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(7) 346.000,918.000,544.015,951.000 'Techup Labs — ( SDE-2 )\\n\\nAugust 2022 - October 2022\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(8) 346.000,846.000,625.727,897.000 'Infosys, Hyderabad — (Senior Systems \\nEngineer\\r)\\n\\nMay 2019- May 2022\\n\\n'>\n",
      "<LTTextBoxHorizontal(9) 653.000,991.000,944.779,1088.000 'EDUCATION\\nNational Institute of Science and Technology, \\nBerhampur \\nTechnology\\r\\n\\n2015 - 2019\\r\\n\\nCgpa of 7.36\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(10) 732.297,1039.000,900.352,1053.000 '— BTECH in Information \\n'>\n",
      "<LTTextBoxHorizontal(11) 653.000,939.000,875.615,972.000 'SKILLS\\n\\nGoogle Data Analytics Certification\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(12) 653.000,848.000,961.809,922.000 'Google Advanced Data Analysis Certification\\nMachine Learning, Data Analytics, Data Vizualisation\\n\\nTechnologies:  Python,R, SQL, Tableau,Excel, \\nJavascript, Angular\\n\\nOthers: Git, CI/CD, Kaggle, Google collab\\n\\n'>\n",
      "<LTTextBoxHorizontal(13) 63.000,737.000,407.611,772.000 'Work Scheduling System - Built using Angular, \\nSAP based API,Bootstrap3\\n'>\n",
      "<LTTextBoxHorizontal(14) 483.000,738.000,910.840,773.000 'Infosys Employee Desk - Built using Angular, Flask,SAP \\nand on premise APo\\n'>\n",
      "<LTTextBoxHorizontal(15) 71.137,706.000,395.355,720.000 '¥ Application catered to entire employees at Poland \\n'>\n",
      "<LTTextBoxHorizontal(16) 84.000,691.000,265.069,704.000 'for scheduling working hour[\\n'>\n",
      "<LTTextBoxHorizontal(17) 71.136,646.000,405.170,690.000 '¥ Designed different roles based on employe \\n¥ SAP API requests and integration(cid:141)\\n¥ Excel upload/download for scheduling and ability to \\n'>\n",
      "<LTTextBoxHorizontal(18) 71.136,601.000,337.495,644.000 'schedule on view  as well(cid:141)\\n¥ Schedule leave or weekly of^\\n¥ Copying schedule to multiple employees \\n'>\n",
      "<LTTextBoxHorizontal(19) 490.555,704.000,892.503,717.000 '¥ Served for team at Internal Systems for employees’ activity like \\n'>\n",
      "<LTTextBoxHorizontal(20) 502.500,689.000,732.219,702.000 'relieving and entering to Organisatiož\\n'>\n",
      "<LTTextBoxHorizontal(21) 490.555,674.000,908.768,687.000 '¥ Smoothend the process of review and analysis by giving Reasons \\n'>\n",
      "<LTTextBoxHorizontal(22) 502.501,659.000,676.195,672.000 'flown from SAP at one plac \\n'>\n",
      "<LTTextBoxHorizontal(23) 490.555,614.000,902.108,657.000 '¥ Easy and Dynamic Search suggestion using Angular Materia²\\n¥ Used Graphs to show data in appealing way(cid:141)\\n¥ Having the ability to choose time frame for accurately seeing the \\n'>\n",
      "<LTTextBoxHorizontal(24) 502.501,599.000,556.925,612.000 'patterns \\n'>\n",
      "<LTTextBoxHorizontal(25) 55.000,546.000,289.082,566.000 ' PROJECTS SHOWCASE\\n'>\n",
      "<LTTextBoxHorizontal(26) 63.000,466.000,499.492,517.000 'Salifort Motors HR Analysis and Machine Leaning \\nModel (Customer Churn)-Logistic regression - Python  \\n(Repository)(cid:141)\\n'>\n",
      "<LTTextBoxHorizontal(27) 71.137,418.000,366.857,464.000 '¥ Performed exploratory Analysiå\\n¥ Trained model to predict Customer Churž\\n¥ Used Logistic Regression \\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(28) 62.999,361.000,470.026,396.000 'Kaggle Trending Youtube Videos Analysis- Python, \\nRepository Î\\n'>\n",
      "<LTTextBoxHorizontal(29) 470.777,380.000,485.202,396.000 ' ( \\n'>\n",
      "<LTTextBoxHorizontal(30) 71.137,329.000,482.589,343.000 '¥ Performed exploratory data analysis on trending YouTube \\n'>\n",
      "<LTTextBoxHorizontal(31) 84.001,313.000,183.093,327.000 'videos in Indi›\\n'>\n",
      "<LTTextBoxHorizontal(32) 71.137,281.000,447.944,311.000 '¥ Analyze trends based on graphs drawn(cid:141)\\n¥ Drew correlation between views comments and likes \\n'>\n",
      "<LTTextBoxHorizontal(33) 84.001,265.000,208.463,279.000 'through heatmaps\\n\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(34) 63.000,237.000,326.794,253.000 'Zomato Restaurant Data Analysis\\n'>\n",
      "<LTTextBoxHorizontal(35) 327.566,237.000,447.225,253.000 '  ( Repository )(cid:141)\\n'>\n",
      "<LTTextBoxHorizontal(36) 71.137,189.000,441.115,219.000 '¥ Did EDA to find relation between different variableå\\n¥  Matplotlib graphs/charts to show outcome\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(37) 62.999,116.000,353.119,170.000 'Data Science Salaries Data Analysis \\n)\\n\\n(cid:141)\\n'>\n",
      "<LTTextBoxHorizontal(38) 353.832,154.000,457.563,170.000 ' ( Repository \\n'>\n",
      "<LTTextBoxHorizontal(39) 71.136,52.000,428.604,114.000 '¥ Kaggle Dataset with usability 1/\\n¥  Did Exploratory Data Analysiå\\n¥ Found out patterns hidden in data and compared \\nthrough seaborn graphs/charts to show relation\\n\\n'>\n",
      "<LTTextBoxHorizontal(40) 528.000,486.000,823.849,521.000 'New York Yellow Taxi Analysis( Time \\nseries) - Python ( Repository Î\\n'>\n",
      "<LTTextBoxHorizontal(41) 536.137,438.000,829.177,468.000 '¥  EDA done through visual Seaborn chartå\\n¥ Performed 2-pair statistical test for \\n'>\n",
      "<LTTextBoxHorizontal(42) 549.001,422.000,677.353,436.000 'hypothesis testinù\\n'>\n",
      "<LTTextBoxHorizontal(43) 536.137,406.000,838.992,420.000 '¥ Prepared  Rainforest model and XGBoost \\n'>\n",
      "<LTTextBoxHorizontal(44) 549.000,390.000,690.716,404.000 'model for prediction\\n\\n'>\n",
      "<LTTextBoxHorizontal(45) 519.000,297.000,897.886,332.000 'Recommendation API - Flask,hosted on Heroku \\n(Repository)Ü\\n'>\n",
      "<LTTextBoxHorizontal(46) 898.684,316.000,947.156,332.000 '(Live) \\n'>\n",
      "<LTTextBoxHorizontal(47) 527.136,265.000,856.693,295.000 '¥ Predict category for content(cid:141)\\n¥ Suggest articles using news api/google news\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(48) 519.000,212.000,814.495,247.000 'Trends API -Flask-Hosted on Heroku \\nRepository Î\\n'>\n",
      "<LTTextBoxHorizontal(49) 815.297,231.000,884.359,247.000 '( Live ) ( \\n'>\n",
      "<LTTextBoxHorizontal(50) 527.137,180.000,835.070,210.000 '¥ Suggest term recommendationå\\n¥ Return trends based on country parameter\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(51) 519.000,107.000,937.564,161.000 'Content Based Recommendation- Machine Learning-\\nScikit Learn,Cosine Similarity, BBC news Dataset \\nRepository\\n'>\n",
      "<LTTextBoxHorizontal(52) 602.953,107.000,612.442,123.000 ' )\\n\\n\\n\\n'>\n",
      "<LTTextBoxHorizontal(53) 911.996,126.000,921.365,142.000 '( \\n'>\n",
      "<LTRect 0.000,0.000,997.000,1100.000>\n",
      "<LTCurve 37.000,20.000,949.000,597.000>\n",
      "<LTTextLineHorizontal 759.133,1070.000,762.619,1084.000 '\\r\\n\\n'>\n",
      "<LTTextLineHorizontal 933.063,908.000,936.287,921.000 ' \\n\\n'>\n",
      "<LTTextLineHorizontal 528.000,375.000,531.224,388.000 ' \\n\\n\\n\\n\\n'>\n"
     ]
    }
   ],
   "source": [
    "for page_layout in extract_pages(\"Rohan AyushCV1.pdf\"):\n",
    "    for elements  in page_layout:\n",
    "        print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohan Ayush\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data Scientist: Expert in Data \n",
      "Anallysis and ML Modeling (Python, \n",
      "R) and Data Visualization (Tableau)\n",
      "\n",
      "Address- Dhurwa,Ranchi, \n",
      "Jharkhand-834004\n",
      "\n",
      "\n",
      "\n",
      "Email -rohanayush05@outlook.com\n",
      "Phone - +91 7992496642\n",
      "\n",
      "LinkedIN\n",
      "\n",
      "\n",
      "WORK PROJECTS\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "DCT,Pune - ( Software Engineer )\n",
      "\n",
      "April,2023  - September,2023\n",
      "\n",
      "\n",
      "\n",
      "Freelance ( Angular Developer )\n",
      "\n",
      "December 2022-  March -2023\n",
      "\n",
      "\n",
      "\n",
      "Techup Labs — ( SDE-2 )\n",
      "\n",
      "August 2022 - October 2022\n",
      "\n",
      "\n",
      "\n",
      "Infosys, Hyderabad — (Senior Systems \n",
      ")ngineer\n",
      "\n",
      "May 2019- May 2022\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "National Institute of Science and Technology, \n",
      "Berhampur \n",
      "Technology\n",
      "\n",
      "2015 - 2019\n",
      "\n",
      "Cgpa of 7.36\n",
      "\n",
      "\n",
      "\n",
      "— BTECH in Information \n",
      "\n",
      "SKILLS\n",
      "\n",
      "Google Data Analytics Certification\n",
      "\n",
      "\n",
      "\n",
      "Google Advanced Data Analysis Certification\n",
      "Machine Learning, Data Analytics, Data Vizualisation\n",
      "\n",
      "Technologies:  Python,R, SQL, Tableau,Excel, \n",
      "Javascript, Angular\n",
      "\n",
      "Others: Git, CI/CD, Kaggle, Google collab\n",
      "\n",
      "\n",
      "Work Scheduling System - Built using Angular, \n",
      "SAP based API,Bootstrap3\n",
      "\n",
      "Infosys Employee Desk - Built using Angular, Flask,SAP \n",
      "and on premise APo\n",
      "\n",
      "¥ Application catered to entire employees at Poland \n",
      "\n",
      "for scheduling working hour[\n",
      "\n",
      "¥ Designed different roles based on employe \n",
      "¥ SAP API requests and integration(cid:141)\n",
      "¥ Excel upload/download for scheduling and ability to \n",
      "\n",
      "schedule on view  as well(cid:141)\n",
      "¥ Schedule leave or weekly of^\n",
      "¥ Copying schedule to multiple employees \n",
      "\n",
      "¥ Served for team at Internal Systems for employees’ activity like \n",
      "\n",
      "relieving and entering to Organisatiož\n",
      "\n",
      "¥ Smoothend the process of review and analysis by giving Reasons \n",
      "\n",
      "flown from SAP at one plac \n",
      "\n",
      "¥ Easy and Dynamic Search suggestion using Angular Materia²\n",
      "¥ Used Graphs to show data in appealing way(cid:141)\n",
      "¥ Having the ability to choose time frame for accurately seeing the \n",
      "\n",
      "patterns \n",
      "\n",
      " PROJECTS SHOWCASE\n",
      "\n",
      "Salifort Motors HR Analysis and Machine Leaning \n",
      "Model (Customer Churn)-Logistic regression - Python  \n",
      "(Repository)(cid:141)\n",
      "\n",
      "¥ Performed exploratory Analysiå\n",
      "¥ Trained model to predict Customer Churž\n",
      "¥ Used Logistic Regression \n",
      "\n",
      "\n",
      "\n",
      "Kaggle Trending Youtube Videos Analysis- Python, \n",
      "Repository Î\n",
      "\n",
      " ( \n",
      "\n",
      "¥ Performed exploratory data analysis on trending YouTube \n",
      "\n",
      "videos in Indi›\n",
      "\n",
      "¥ Analyze trends based on graphs drawn(cid:141)\n",
      "¥ Drew correlation between views comments and likes \n",
      "\n",
      "through heatmaps\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zomato Restaurant Data Analysis\n",
      "\n",
      "  ( Repository )(cid:141)\n",
      "\n",
      "¥ Did EDA to find relation between different variableå\n",
      "¥  Matplotlib graphs/charts to show outcome\n",
      "\n",
      "\n",
      "\n",
      "Data Science Salaries Data Analysis \n",
      ")\n",
      "\n",
      "(cid:141)\n",
      "\n",
      " ( Repository \n",
      "\n",
      "¥ Kaggle Dataset with usability 1/\n",
      "¥  Did Exploratory Data Analysiå\n",
      "¥ Found out patterns hidden in data and compared \n",
      "through seaborn graphs/charts to show relation\n",
      "\n",
      "\n",
      "New York Yellow Taxi Analysis( Time \n",
      "series) - Python ( Repository Î\n",
      "\n",
      "¥  EDA done through visual Seaborn chartå\n",
      "¥ Performed 2-pair statistical test for \n",
      "\n",
      "hypothesis testinù\n",
      "\n",
      "¥ Prepared  Rainforest model and XGBoost \n",
      "\n",
      "model for prediction\n",
      "\n",
      "\n",
      "Recommendation API - Flask,hosted on Heroku \n",
      "(Repository)Ü\n",
      "\n",
      "(Live) \n",
      "\n",
      "¥ Predict category for content(cid:141)\n",
      "¥ Suggest articles using news api/google news\n",
      "\n",
      "\n",
      "\n",
      "Trends API -Flask-Hosted on Heroku \n",
      "Repository Î\n",
      "\n",
      "( Live ) ( \n",
      "\n",
      "¥ Suggest term recommendationå\n",
      "¥ Return trends based on country parameter\n",
      "\n",
      "\n",
      "\n",
      "Content Based Recommendation- Machine Learning-\n",
      "Scikit Learn,Cosine Similarity, BBC news Dataset \n",
      "Repository\n",
      "\n",
      " )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "( \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "text = extract_text(\"Rohan AyushCV1.pdf\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python, ', 'Ranchi, ', 'Infosys, ', 'Technology, ', 'Learning, ', 'Analytics, ', 'R, ', 'SQL, ', 'Excel, ', 'Javascript, ', 'Git, ', 'CD, ', 'Kaggle, ', 'Angular, ', 'Angular, ', 'Python, ', 'Similarity, ']\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r\"[A-Za-z]+,{1}\\s{1}\")\n",
    "matches = pattern.findall(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'Ranchi', 'Infosys', 'Technology', 'Learning', 'Analytics', 'R', 'SQL', 'Excel', 'Javascript', 'Git', 'CD', 'Kaggle', 'Angular', 'Angular', 'Python', 'Similarity']\n"
     ]
    }
   ],
   "source": [
    "names = [n[:-2] for n in matches]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # from pip install PyMuPDF\n",
    "import PIL.Image # from pillow\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fitz.open(\"Encyclopedia of Extinct Animals.pdf\")\n",
    "counter = 1\n",
    "#scalable\n",
    "for i in range(len(pdf)):\n",
    "    page = pdf[i]\n",
    "    images = page.get_images()\n",
    "    for image  in images:\n",
    "        base_img = pdf.extract_image(image[0])\n",
    "        image_data = base_img[\"image\"]\n",
    "        img = PIL.Image.open(io.BytesIO(image_data))\n",
    "        extension = base_img['ext']\n",
    "        img.save(open(f\"image{counter}.{extension}\",\"wb\"))\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_csv(input_file,output_file_name):\n",
    "    tables = tabula.read_pdf(input_file, pages='all', multiple_tables=True)\n",
    "    if(tables):\n",
    "        for table_num,table in enumerate(tables):\n",
    "            df = pd.DataFrame(table)\n",
    "            df['table_number']=table_num + 1\n",
    "            output = output_file_name+str(table_num +1)+\".csv\"\n",
    "            df.to_csv(output, index=False, encoding='utf-8')\n",
    "            print(f\"Files saved at {output}\")\n",
    "    else:\n",
    "        print('No tables found in the PDF.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved at output file of table.pdf1.csv\n"
     ]
    }
   ],
   "source": [
    "input_pdf_path = 'table.pdf' \n",
    "output_csv_path = f'output file of {input_pdf_path}'\n",
    "pdf_to_csv(input_pdf_path,output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with nested pdf tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nested_data(table):\n",
    "    # Function to extract data from nested columns\n",
    "    nested_data = []\n",
    "    for df in table:\n",
    "        if 'Gender' in df.columns and 'M' in df['Gender'] and 'F' in df['Gender']:\n",
    "            for _, row in df.iterrows():\n",
    "                gender_data = {\n",
    "                    'Name': row['Name'],\n",
    "                    'Age': row['Age'],\n",
    "                    'Gender_M': row['Gender']['M'],\n",
    "                    'Gender_F': row['Gender']['F']\n",
    "                }\n",
    "                nested_data.append(gender_data)\n",
    "    return nested_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    Unnamed: 0    Unnamed: 1 Unnamed: 2   Unnamed: 3    Unnamed: 4  \\\n",
      "0          NaN           NaN        NaN      Ballots           NaN   \n",
      "1   Disability           NaN    Ballots          NaN           NaN   \n",
      "2          NaN  Participants        NaN  Incomplete/           NaN   \n",
      "3     Category           NaN  Completed          NaN      Accuracy   \n",
      "4          NaN           NaN        NaN   Terminated           NaN   \n",
      "5          NaN           NaN        NaN          NaN           NaN   \n",
      "6        Blind             5          1            4    34.5%, n=1   \n",
      "7   Low Vision             5          2            3     98.3% n=2   \n",
      "8          NaN           NaN        NaN          NaN  (97.7%, n=3)   \n",
      "9    Dexterity             5          4            1    98.3%, n=4   \n",
      "10    Mobility             3          3            0    95.4%, n=3   \n",
      "\n",
      "            Results  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3           Time to  \n",
      "4               NaN  \n",
      "5          complete  \n",
      "6     1199 sec, n=1  \n",
      "7     1716 sec, n=3  \n",
      "8   (1934 sec, n=2)  \n",
      "9   1672.1 sec, n=4  \n",
      "10    1416 sec, n=3  ]\n"
     ]
    }
   ],
   "source": [
    "input_pdf_path = 'table.pdf' \n",
    "output_csv_path = f'output file of {input_pdf_path}'\n",
    "tables = tabula.read_pdf(input_pdf_path, pages='all', multiple_tables=True)\n",
    "print(tables)\n",
    "# nested_data= extract_nested_data(tables)\n",
    "# print(nested_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ballots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disability</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ballots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Participants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incomplete/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Time to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blind</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34.5%, n=1</td>\n",
       "      <td>1199 sec, n=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Low Vision</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>98.3% n=2</td>\n",
       "      <td>1716 sec, n=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(97.7%, n=3)</td>\n",
       "      <td>(1934 sec, n=2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dexterity</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>98.3%, n=4</td>\n",
       "      <td>1672.1 sec, n=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mobility</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>95.4%, n=3</td>\n",
       "      <td>1416 sec, n=3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    Unnamed: 1 Unnamed: 2   Unnamed: 3    Unnamed: 4  \\\n",
       "0          NaN           NaN        NaN      Ballots           NaN   \n",
       "1   Disability           NaN    Ballots          NaN           NaN   \n",
       "2          NaN  Participants        NaN  Incomplete/           NaN   \n",
       "3     Category           NaN  Completed          NaN      Accuracy   \n",
       "4          NaN           NaN        NaN   Terminated           NaN   \n",
       "5          NaN           NaN        NaN          NaN           NaN   \n",
       "6        Blind             5          1            4    34.5%, n=1   \n",
       "7   Low Vision             5          2            3     98.3% n=2   \n",
       "8          NaN           NaN        NaN          NaN  (97.7%, n=3)   \n",
       "9    Dexterity             5          4            1    98.3%, n=4   \n",
       "10    Mobility             3          3            0    95.4%, n=3   \n",
       "\n",
       "            Results  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3           Time to  \n",
       "4               NaN  \n",
       "5          complete  \n",
       "6     1199 sec, n=1  \n",
       "7     1716 sec, n=3  \n",
       "8   (1934 sec, n=2)  \n",
       "9   1672.1 sec, n=4  \n",
       "10    1416 sec, n=3  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(tables[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_nested_table(data):\n",
    "    flat_data = []\n",
    "\n",
    "    current_category = None\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        if pd.notna(row['Unnamed: 0']):\n",
    "            current_category = row['Unnamed: 0']\n",
    "\n",
    "        flat_row = {'Category': current_category}\n",
    "\n",
    "        for col in data.columns:\n",
    "            if pd.notna(row[col]) and col != 'Category':\n",
    "                flat_row[col] = row[col]\n",
    "\n",
    "        flat_data.append(flat_row)\n",
    "\n",
    "    return flat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(flatten_nested_table(data))\n",
    "df1.to_csv(\"table.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
